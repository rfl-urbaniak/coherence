---
title: "Structured probabilistic coherence \\linebreak and the usual counterexamples to probabilistic measures of coherence"
# author: 
#   - "\\normalsize Rafal Urbaniak ([LoPSE research group](http://lopsegdansk.blogspot.com/p/lopse-team.html), University of Gdansk)"
#   - "\\normalsize Alicja Kowalewska  (Carnegie Mellon University \\& [LoPSE research group](http://lopsegdansk.blogspot.com/p/lopse-team.html))" 
output:
  bookdown::pdf_document2:
    number_sections: true
    df_print: kable 
    keep_tex: true
    toc_depth: 3
    includes:
      in_header:
        - Rafal_latex7.sty
fontsize: 10pt
bibliography: coherence.bib
csl: apa-6th-edition.csl 
documentclass: scrartcl
linkcolor: blue 
filecolor: blue
citecolor: blue
urlcolor: blue
toccolor: blue
---
\setlength{\abovedisplayskip}{-10pt}
\setlength{\belowdisplayskip}{5pt}

```{r setup, include=FALSE, echo=FALSE}
require("knitr")
knitr::opts_chunk$set(fig.pos = "H")
#opts_knit$set(root.dir = "../code")

```


```{r setup2, include=FALSE, cache = TRUE}
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(bnlearn)
library(knitr)
library(kableExtra)
library(gRain)
library(reshape2)
library(tidyverse)
library(plyr)
library(rje)
library(bnlearn)
library(utils)
library(latex2exp)
library(useful)
library(tidyverse)
library(stringr)
library(plot3D)
library(tinytex)


source("../code/utils//CombinationsBN.R")
source("../code/utils//CptCreate.R")
source("../code/utils//LogicAndBNs.R")
source("../code/utils//kableCPTs.R")
source("../code/utils//CoherenceTables.R")
source("../code/measures/Fitelson.R")
source("../code/measures/DouvenMeijs.R")
source("../code/measures/generalizedOlsson.R")
source("../code/measures/generalizedShogenji.R")
source("../code/measures/Olsson.R")
source("../code/measures/Roche.R")
source("../code/measures/Shogenji.R")
source("../code/measures/structuredCoherenceLR.R")
source("../code/measures/structuredCoherenceNarr2.R")
```


\pagebreak 


# Introduction \& motivations



The notion of coherence is often used in many philosophical, especially epistemological, discussions (for instance, in discussions  about the  truth-conduciveness of coherence).  When we talk about the coherence of a set of propositions or about the coherence of a story, we seem to  refer to   how well their individual pieces fit together.  How are we to understand and apply this notion systematically, though? In particular, we will be interested in probabilistic explications of this notion, as Bayesian epistemology strives to be a general epistemological project and as such it should be able to accommodate coherence-oriented considerations. 




There is also a  more practical  reason to develop a better understanding of the notion: a plausible measure of coherence could be used to better evaluate the quality of some stories or narrations. For example in the legal context we would like to be able to assess the quality of a testimony in the court of law.  
<!-- \todo{REFS} -->

<!-- Allen R (2010) No plausible alternative to a plausible story of guilt as the rule of decision in criminal cases. In: Cruz, J., Laudan, L. (eds) Proof and standards of proof in the law. Northwestern University School of Law, pp 10–27 -->

<!-- Pennington N, Hastie R (1991) A cognitive theory of juror decision making: the story model. Cardozo Law Rev. 13:519–557 -->

<!-- Spottswood M (2013) Bridging the gap between Bayesian and story-comparison models of juridical inference. Law Probab Risk, pp. mgt010 -->

<!-- Vlek C (2016) When stories and numbers meet in court: constructing and explaining Bayesian networks for criminal cases with scenarios. Rijksuniversiteit Groningen -->



<!-- Focusing only on the probability of a story is to some extent problematic, because from such a perspective, more detailed stories are  penalized --- they contain more propositions, so they (usually) have lower probabilities. A plausible coherence measure could be used to asses an important aspect of a narration which so far seems to escape probabilistic analysis.  -->




Multiple probabilistic explications of coherence have been proposed 
[@shogenji1999conducive; @olsson2001conducive; @glass2002; @fitelson2003ProbabilisticTheoryCoherence; @Douven2007measuring; @Meijs2007Alleged; @Roche2013Coherence].  However, clear general principles to choose between them are hard to come by. One paper where some such principles have been formulated is [@Schippers2014Probabilistic], where a list of seemingly plausible adequacy conditions for a coherence measure is proposed and shown to be inconsistent to argue for pluralism about the notion of coherence. However, some of those requirements are quite non-trivial.^[Let us illustrate this.  The (Dependence) condition formulated there requires that the coherence score of a set of propositions is above (below) the neutral score if for all pairs of non-empty subsets  the posterior of an element of a pair conditional on the other element is higher than the prior of the former. This makes some of the features of the coherence measure dependent on the priors, and whether it should be so is not obvious.  On the other hand, (Agreement) is formulated in terms of conditional probabilities between such pairs. If on a given measure $\mathsf{P}$ all conditional probabilities (between pairs already mentioned) are higher than on $\mathsf{P}'$, the coherence of a set given $\mathsf{P}$ should be higher than given $\mathsf{P}'$.   The (Equivalence) requirement is that any  finite set of logically equivalent propositions should be maximally coherent. This is suspicious, as the set $\{ 0= 1, 2, = 5\}$ is a set of equivalent propositions (with sufficiently strong notion of logical equivalence in the background), but we would intuitively hesitate to say it's maximally coherent.]

The general point here is not that the approach taken in [@Schippers2014Probabilistic] is flawed, but rather that the task of formulating general principles for coherence is a challenge, and that  no clear list of such uncontroversial desiderata is on the horizon.

One approach to obtaining some clarity on which abstract conditions are plausible is looking at various thought experiments in which our intuitions about what the coherence scores should be (at least comparatively) are more robust than direct assessment of general requirements. In fact, looking at examples is what the main stream of literature on probabilistic coherence focused on, and each probabilistic measure of coherence faces a selection of seemingly intuitive counterexamples.  

We decided to work with this methodology. We first gathered key examples that occur in the literature, represented them in terms of Bayesian networks, and developed \textbf{\textsf{R}} scripts calculating all coherence scores for the Bayesian networks at play, pushing further the results obtained by @koscholke2016evaluating.^[
The whole work has been made possible by all those who contributed to the development of \textsf{\textbf{R}} language, and Marco Scutari, the author of \textsf{\textbf{bnlearn}} package, who was kind enough to extend his package with additional features upon our requests [@Scutari2015Bayesian-Networ].]  Then we reflected on the results, noticing that one weakness of the measures is that they pay little attention to the underlying structure  of a given narration in the calculation of its coherence. 

Inspired by this observation, we formulate our own proposal, which  diverges from the known purely probabilistic measures of coherence in three important respects: (i) It is not a function of a probability measure and a set
of propositions alone, because it is also sensitive to the selection and direction of edges in a Bayesian network representing an agent's credal state. (ii) Unlike in the case of quite a few coherence measures, it is  sensitive to
 the  weakest links in the narration. (iii) It is not obtained by simply averaging confirmation levels between all possible combinations of elements. 

We described this approach in a more detailed introduction to this measure [ANONYMIZED], which explains the method and some of the theoretical decisions that we have made, and show how it works using a  Bayesian network developed for the well-known Sally Clark case [@Fenton2018Risk]. The goal of the current  paper is to discuss a range of philosophical counterexamples to the existing  probabilistic measures of coherence and evaluate the performance of our approach using those as a benchmark, arguing that it performs much better than the existing ones. 

Accordingly, in Section \ref{sec:measures} we introduce all the coherence measures, including the key motivations for and a pseudo-code description of our measure. In Section \ref{sec:examples} we describe the thought experiments meant as counterexamples to coherence measures, their corresponding desiderata and their status on various coherence measures, including ours. The order of the  discussion of any given example is straightforward: we first explain what the situation we are to consider is, what the intuitive desiderata related to it are supposed to be, how the situation is represented by means of a Bayesian network(s), and what happens when we apply all coherence measures. We end with  Section \ref{sec:discussion} in which we compare all of the results and draw some general conclusions. 



























# Probabilistic coherence measures and structured coherence

\label{sec:measures}

Quite a few different measures of coherence have been proposed in the literature.  Two early proposals are:

-  Shogenji's 
  \textbf{deviation from independence} [@shogenji1999conducive], is defined as the ratio between the probability of the
conjunction of all claims, and the probability that the conjunction
would get if all its conjuncts were probabilistically independent (scaling from 0 to $\infty$ with neutral point 1):



\begin{align}
    \tag{Shogenji}
    \label{coh:Shogenji}
     \mathcal{C}_{S}(S)=\frac{P(\bigwedge S)}{\prod_{i=1}^{\vert S \vert}\{P(S_i)\vert i \in S\}}
\end{align}

\noindent This measure was later generalized by @Meijs2007Alleged. According to this approach, \eqref{coh:Shogenji} is applied not only to the whole set of propositions, but to each non-empty non-singleton subset of the set, and  the final value is defined as the average of all sub-values thus obtained.

-   \textbf{Relative overlap}  [@olsson2001conducive; @glass2002], is defined as the ratio  between the intersection of all propositions and their union (scaling from -1 to 1 with no clear neutral point):

\begin{align}
    \tag{Olsson}
    \label{coh:Olsson}
    \mathcal{C}_{O}(S)=\frac{P(\bigwedge S)}{P(\bigvee S)}
\end{align}

\noindent It has also been generalized in a way analogous to the one used in the generalization of  the Shogenji's measure [@Meijs2007Alleged].

Both of these approaches are susceptible to various objections and counterexamples [@Merricks1995; @shogenji1999conducive; @Akiba2000Shogenjis; @Shogenji2001Reply; @bovens2004bayesian; @Siebel2004On-Fitelsons-me; @siebel2006against; @Shogenji2006Why; @crupi2007BayesianMeasuresEvidential; @koscholke2016evaluating; @Schippers2019General]. To overcome them, more recent works proposed \textbf{average mutual support} measures, starting with [@fitelson2003ProbabilisticTheoryCoherence]. The general recipe for such measures is as follows.


\begin{itemize}
\item
  Given that \(S\) is a set whose coherence is to be measured, let \(P\)
  indicate the set of all ordered pairs of non-empty, disjoint subsets
  of \(S\).
\item
  First, define a confirmation function (of  a hypothesis \(H\) by evidence  \(E\)): \(\mathsf{conf}(H,E)\).
\item
  For each pair \(\langle X, Y \rangle \in P\), calculate
  \(\mathsf{conf}(\bigwedge X, \bigwedge Y)\), where $\bigwedge X$  is the conjunction of all the elements of $X$ (and $\bigwedge Y$ is to be understood analogously).
\item
  Take the mean of all the results:
\end{itemize}\begin{align*}
    \mathcal{C}(S) & =
\mathsf{mean}\left(\left\{\mathsf{conf}(\bigwedge X_i, \bigwedge Y_i) | \langle X_i, Y_i \rangle \in P\right\} \right).
\end{align*}

\noindent Different measures of coherence result from different choices of a confirmation measure. Here are the key candidates present in the literature:


-  @fitelson2003ProbabilisticTheoryCoherence   uses the following confirmation function (the resulting coherence measure ranges from -1 to 1 with neutral point at 0):

\begin{align}
    F(H,E) & = \begin{cases}
    1 & E\models H, E\not \models \bot \\
    -1 & E \models \neg H\\
    \frac{P(E|H)-P(E|\neg H)}{P(E|H)+P(E|\neg H)} & \mbox{o/w}
    \end{cases} \nonumber \\
\tag{Fitelson}  
    \mathcal{C}_{F}(S) & =
\mathsf{mean}\left(\left\{F(\bigwedge X_i, \bigwedge Y_i) | \langle X_i, Y_i\rangle \in P\right\} \right)
\end{align}


-  @Douven2007measuring  use the difference confirmation measure (with coherence ranging from -1 to 1 with neutral point at 0):

\begin{align}
    D(H,E) &= P(H|E) - P(H) \nonumber \\
\tag{DM}  
    \mathcal{C}_{DM}(S) & =
\mathsf{mean}\left(\left\{D(\bigwedge X_i, \bigwedge Y_i) | \langle X_i, Y_i\rangle \in P\right\} \right)
\end{align}


-  @Roche2013Coherence uses the absolute confirmation measure 
(the resulting coherence measure ranges from 0 to 1 with neutral point at $0.5$): 

\begin{align} \nonumber 
    A(H,E)  & = \begin{cases}
    1 & E\models H, E\not \models \bot \\
    0 & E \models \neg H\\
    P(H|E) & \mbox{o/w} \\
    \end{cases} \\
\tag{Roche}  
    \mathcal{C}_{R}(S) & =
\mathsf{mean}\left(\left\{A(\bigwedge X_i, \bigwedge Y_i) | \langle X_i, Y_i\rangle \in P\right\} \right) 
\end{align}

Mind your head: different measures use different scales and have different neutral points (values  taken for any set of probabilistically independent propositions; not all measures have neutral points).  This is worth keeping in mind when it comes to various desiderata that we will discuss. 

As we already mentioned in the introduction,  formulating abstract formal requirements for a coherence measure and investigating whether a given coherence measure satisfies them has not resulted in an agreement. For this reason, we follow another path, which has dominated the literature on the topic.  We look at how the measures behave in test scenarios. Many putative scenarios were  put forward as counterexamples. They usually have the form of a few propositions formulated in natural language, such that intuitive judgments of coherence involved and the formal coherence calculations  seem to diverge [@shogenji1999conducive; @bovens2004bayesian; @Meijs2007Alleged; @Merricks1995;  @Meijs2007Alleged; @Siebel2004On-Fitelsons-me; @siebel2006against; @Shogenji2006Why; @Akiba2000Shogenjis; @Shogenji2001Reply; @Schippers2019General; @koscholke2016evaluating; @Schippers2019General]. We will focus on these examples in what follows. To spoil the experience, let us already point out that the probabilistic measures we introduced above do not  seem to handle these examples very well (read on for details). 

Inspired by these failures, in [REFERENCE SUPRESSED FOR ANONYMITY] we proposed to take a different perspective. Putting the earliest measures aside (they were problematic for various reasons), we noticed that the problems with the average mutual support measures stem from the fact that the coherence score is an average confirmation score for all possible combinations of the parts of a narration. Therefore we proposed to take a more fine-grained account. First, we represented an agent's belief state by means of a Bayesian network, which comprises not only a probabilistic measure but additional structural information, Then we used this structural information in our definition of coherence, so that only those directions of support are considered which in fact are indicated by the structure of the agent's belief state.



While we refer the reader to a more extensive treatment in [REFERENCE SUPRESSED FOR ANONYMITY], we now briefly discuss the main idea behind it. A Bayesian network represents agent's probabilistic belief state with respect to the relevant nodes. Some of them are distinguished as fixed narration nodes---the agent holds definite beliefs about which states of these nodes occur.

Each parented node in the BN receives its expected confirmation score (\s{ECS}). It is calculated by looking at all combinations of its states and states of its parents not excluded by agents' fixed beliefs. For each of these combinations, the confirmation score between the parents' states and the child state is calculated (in the pseudo-code, we use confirmation measure \s{Z}, in further calculations we also use measures \s{LR} and \s{L} for comparison)^[DEFINITIONS]. Then, a weighted average of these scores is obtained, where weights are the probabilities of the combinations of parents' states obtained by  updating the BN  with the fixed states of the fixed narration nodes. The final coherence score is either the mean of the \s{ecs} scores, if all of them are positive, or it is a weighted average of their mean and their minimum, $(1- |\s{min}(\s{ecs})|) \times \s{mean}(\s{ecs}) + |\s{min}(\s{ecs})| \times \s{min}(\s{ecs})$, otherwise.^[We have developed \textbf{\textsf{R}} code calculating this and other measures to handle calculations that will be discussed further on, the code with documentation is available at ANONYMIZED.]




\pagebreak 
\footnotesize 

```{r eval = FALSE, highlight = FALSE}

FUNCTION parents_child_possible_states(parents,child)
    IF child included in narration THEN
        consequentStates <- the unique state of child as reported in the narration
    ELSE
        consequentStates <- all possible states of child
    FOR EACH parent in parents
        IF parent included in narration THEN
            parentStates[parent] <- the unique state of parent as reported in the narration
        ELSE
            parentStates[parent] <- all possible states of parent
    parentsStates <- all combinations of parentStates
    variants <- list of all possible combinations of consequentStates and parentsStates
    RETURN variants


FUNCTION coherence_from_ecs(ecs)
    IF min(ecs) <= 0 THEN
        RETURN mean(ecs) * (min(ecs)+1) - min(ecs)min(ecs)
        #this is equivalent to (1- |min(ecs)|) * mean(ecs) + |min(ecs)| * min(ecs)
    ELSE
        RETURN mean(ecs)

FUNCTION structured_coherence(BN,fixedNodes,fixedStates)
    parentedNodes <- vector of non-root nodes in BN
    ecsList <- []
    FOR EACH parentedNode IN parentedNodes
        variants <- parents_child_possible_states(parents,parentedNode)
        variants_count <- length(variants)
        sumParentsNarr <- 0
        FOR EACH variant IN variants
            childPrior <- prior probability of the child state in variant
            childPosterior <- posterior probability of the child state in variant,
                        obtained by updating on the parents states
                        from this variant
            parentsNarr[variant] <- joint probability of 
                        the parents states in variant in BN updated with fixedStates of fixedNodes
            sumParentsNarr <- sumParentsNarr +  parentsNarr[variant] 
            z[variant] <- z_confirmation_measure(childPrior, childPosterior)
        ecs <- 0  #expected confirmation score
        FOR EACH variant IN variants
            IF parentsNarr[variant] > 0 THEN
                weight <- parentsNarr[variant]/sumParentsNarr
            ELSE
                weight <- 1/variants_count
            zScaled <- z[variant] * weight
            ecs <- ecs + zScaled
        ecsList.add(ecs)
    RETURN coherence_from_ecs(ecsList)
```
\normalsize 

 
\noindent Having introduced the coherence measures at play, let us now move to the key counterexamples discussed in the literature.


# Challenges and their treatment  \label{sec:examples}

For each of the counterexamples, we first explain what it is and what the connected desiderata are. Then  we represent it as a Bayesian network, and finally we use our \textbf{\textsf{R}} scripts to calculate coherence scores that the coherence measures included in the previous section (including ours) yield for a given example and whether the desiderata are satisfied. 
Here are the counterexamples put forward against various coherence measures in the literature. We ignored only a few  where both we didn't share the authors' intuitions and the examples were not picked up in further discussion in the literature. 




## Penguins


\textbf{The scenario.}  A challenge discussed in [@bovens2004bayesian,50] and [@Meijs2007Alleged] consists of the  propositions (instead of \emph{letters} or \emph{abbreviations}, we'll talk about \emph{nodes}, as these will be used later on in Bayesian networks) displayed in Table \@ref(tab:penguinsPropositions). 

```{r penguinsPropositions,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
source("../code/bns/Penguins.R")
B <- "Tweety is a bird."
G <-  "Tweety is a grounded animal."
P <-   "Tweety is a penguin."


penguin <- data.frame(c("B","G","P"),c(B,G,P))
colnames(penguin) <- c("node","content")
penguinsPropositions <- penguin %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, 
                        caption = "Propositions in the Penguins scenario") %>%   
                          kable_styling(latex_options=c("striped","HOLD_position")) 
penguinsPropositions
```




\noindent \textbf{Desiderata.}
It seems that the set \{\s{B},\s{G}\}, which doesn't contain the information about Tweety being a penguin, should be less coherent than the one that does contain this information: \{\s{B},\s{G},\s{P}\}.

\vspace{2mm}\begin{description}
    \item[(\s{BG}$<$\s{BGP})] \{\s{B},\s{G}\}  should be less coherent than \{\s{B},\s{G},\s{P}\}. 
\end{description}\vspace{2mm}

Another intuition about this scenario [@Schippers2019General] is that when you consider a set which says that Tweety is both a bird and a penguin: \{\s{B},\s{P}\}, adding proposition about not flying (\s{G}) shouldn't  increase the coherence of the set as much as moving from \{\s{B},\s{G}\} to \{\s{B},\s{G}, \s{P}\}.  It's a well-known fact that penguins don’t fly and by adding \s{G} explicitly to the set, one wouldn't gain as much information. 
However, as \s{G} is not a logical consequence of \s{P}, it can be argued that \{\s{B},\s{P}\} and \{\s{B},\s{P},\s{G}\} represent different information sets, and so some  difference in their coherence is  to be expected.

\vspace{2mm}\begin{description}
    \item[(\s{BG} $\ll$ \s{BP}$\leq$\s{BGP})]  \{\s{B},\s{P}\} should be notably above  \{\s{B},\s{G}\}, and less than \{\s{B},\s{P},\s{G}\}.
\end{description}\vspace{2mm}

\noindent Formally, we'll require that the absolute difference between \s{BG} and \s{BP} be greater than $.1$ (the exact placement of the threshold doesn't make a huge difference, unless it's at an unintuitive value below  $.01$) and that \{\s{B},\s{G}\} $\leq$  \{\s{B},\s{P},\s{G}\}.


\noindent \textbf{Bayesian network.} We used the distribution used in the original formulation to build a BN corresponding to the narrations at play (Fig. \ref{fig:BGP}).\footnote{Not without concerns. There are around 18 000 species of birds, and around 60 of them are flightless. We  couldn't find information about counts, but it seems the probability of being a penguin if one is grounded is overestimated by philosophers.  Also, there are many things that are not grounded but are not birds, mostly insects, and there's plenty of them. We did spend some time coming up with plausible ranges of probabilities to correct for such factors, and none of them actually makes a difference to the main point. So, for the sake of simplicity, we leave the original unrealistic distribution in our discussion.}



\begin{figure}[H]
\hspace{2cm}\scalebox{0.7}{\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "100%", dpi = 300}
source("../code/bns//Penguins.R")
 
graphviz.plot(BirdDAGbgp)
```
\end{subfigure}} \hfill
\hspace{-3cm}\scalebox{0.8}{\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%", dpi = 300}
source("../code/utils//kableCPTs.R")
CPkable0("BirdBNbgp","B")
CPkable1("BirdBNbgp","P")
CPkable2("BirdBNbgp","G")
```
\end{subfigure}}
\caption{Bayesian network for the Penuins problem.}
\label{fig:BGP}
\end{figure}




\begin{figure}[H]
\hspace{2cm}\scalebox{0.6}{
\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%",  dpi = 300, fig.height=2.5, fig.width=2}
graphviz.plot(BirdDAGbg)
```
\end{subfigure} }
\hfill
\hspace{-3cm}\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%", dpi = 300}
CPkable0("BirdBNbg","B")
CPkable1("BirdBNbg","G")
```
\end{subfigure}
\label{fig-BG}
\caption{Bayesian network for the \textsf{BG} scenario.}
\end{figure}



\begin{figure}[H]
\scalebox{0.6}{
\hspace{4cm}\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", dpi = 300, fig.width=2, fig.height= 2.5}
graphviz.plot(BirdDAGbp)
```
\end{subfigure}} \hfill
\hspace{-3cm}\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%", dpi = 300}
CPkable0("BirdBNbp","B")
CPkable1("BirdBNbp","P")
```
\end{subfigure}
\caption{Bayesian network for the \textsf{BP} scenario.}
\label{fig:BP}
\end{figure}







\noindent \textbf{Results.} Now, let's calculate the coherence scores (Table \@ref(tab:penguinsCoherence)) and see if the desiderata are satisfied (Table \@ref(tab:penguinsDesiderata)).  The measures are: Olsson-Glass, generalized Olsson-Glass, Shogenji, generalized Shogenji, Douven-Meijs, Roche, Fitelson, Structured with Z, LR, and L used as a confirmation measure.


```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE, fig.show = "hold", out.width = "100%"}
BGP <- c("B","G","P")
BG <- c("B","G")
BP <- c("B","P")

penguinsTableNarr <- CoherencesTableNarr(list(BirdBNbgp,BirdBNbg,BirdBNbp), scenariosList = list(BGP, BG, BP), statesList   = list(c("1","1","1"), c("1","1"), c("1","1")),exampleName = "Penguins")

# penguinsTableBGP <- CoherencesTable(BirdBNbgp, scenariosList = list(BGP), statesList   = list(c("1","1","1")),exampleName = "Penguins")
#
# penguinsTableBG <- CoherencesTable(BirdBNbg, scenariosList = list(BG), statesList   = list(c("1","1")),exampleName = "Penguins")
#
# penguinsTableBP <- CoherencesTable(BirdBNbp, scenariosList = list(BP), statesList   = list(c("1","1")),exampleName = "Penguins")

#penguinsTable <- rbind(penguinsTableBGP,penguinsTableBG,penguinsTableBP)
```



```{r penguinsCoherence,echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE, fig.show = "hold", out.width = "100%"}
library(tidyverse)
round(penguinsTableNarr,3) %>%  kable(format = "latex",booktabs=T,
  linesep = "",  escape = FALSE, caption = "Coherence scores for the Penguins scenario (rounded). Note how LR might result in Inf if a conditional probability of 1 at an arrow used in the calculations is involved.") %>%
  kable_styling(latex_options=c("striped","scale_down","HOLD_position"))
```




```{r ,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
BGlessBGP <- penguinsTableNarr[1,] > penguinsTableNarr[2,]
#BPatleastBGP <- round(penguinsTable[3,],4) >= round(penguinsTable[1,],4)
BPbetweenBGandBGP <-  abs(penguinsTableNarr[3,] - penguinsTableNarr[2,]) >.1 & abs(penguinsTableNarr[1,] - penguinsTableNarr[3,]) >=0

penguinsResults <- as.data.frame(rbind(BGlessBGP,BPbetweenBGandBGP))
rownames(penguinsResults) <- c("Penguins: BG$<$BGP","Penguins: BG$<<$ BP$<$ BGP")
```

```{r penguinsDesiderata,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%", message = FALSE, warning = FALSE}
library(tidyverse)
library(kableExtra)
penguinsResults %>%  kable(format = "latex",booktabs=T, linesep = "",  escape = FALSE, caption = "Desiderata satisfaction for the Penguins scenario.") %>%
   kable_styling(latex_options=c("striped","scale_down","HOLD_position"))
```







## Dunnit



\textbf{The scenario.} Another challenge, introduced by  @Merricks1995 goes as follows:  Mr. Dunnit is a suspect in the murder case. Detectives first obtained the body of evidence specified in Table \@ref(tab:dunnitPropositions1).


```{r dunnitPropositions1,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
source("../code/bns/Dunnit.R")
I <- "Witnesses claim to have seen Dunnit do it (incriminating testimony)."
M <-  "Dunnit had a motive for the murder."
W <-   "A credible witness claims to have seen Dunnit two hundred miles from the scene of the crime at the time of the murder."


dunnit <- data.frame(c("I","M","W"),c(I,M,W))
colnames(dunnit) <- c("node","content")
dunnit %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, caption = "Initial evidence in the Dunnit scenario.") %>%  
  kable_styling(latex_options=c("striped","HOLD_position")) %>%
  column_spec(2, width = "25em")
```


\noindent In light of this information they try to assess whether Dunnit is responsible for the crime (Table \@ref(tab:dunnitPropositions2).


```{r dunnitPropositions2,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
G <-  "Dunnit is guilty."

dunnit <- data.frame(c("G"),c(G))
colnames(dunnit) <- c("node","content")
dunnit %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, caption = "The guilt statement in the Dunnit scenario.") %>%
  kable_styling(latex_options=c("striped","HOLD_position")) %>% column_spec(2, width = "25em")
```

\noindent Now, suppose the detectives learn Dunnit has a twin brother (Table \@ref(tab:dunnitPropositions3)). 

```{r dunnitPropositions3,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "100%"}
source("../code/bns/Dunnit.R")
Tw <- "Dunnit has an identical twin which was seen by the credible witness two hundred miles from the scene of the crime during the murder."

dunnit <- data.frame(c("Tw"),c(Tw))
colnames(dunnit) <- c("node","content")
dunnit %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, caption = "New evidence in the Dunnit scenario.") %>% 
  kable_styling(latex_options=c("striped","HOLD_position")) %>% column_spec(2, width = "25em")
```





\noindent What are our intuitions when we compare the coherence of $\{$\s{I,M,W,G}$\}$ with the coherence of   $\{$\s{I,M,W,G,Tw}$\}$? 


\noindent \textbf{Desideratum.}  It seems that adding proposition about a twin should increase the coherence of the set.

\vspace{2mm}\begin{description}
    \item[(Dunnit$<$Twin)] $\{$\s{I,M,W,G}$\}$ should be less coherent than $\{$\s{I,M,W,G,Tw}$\}$. 
\end{description}\vspace{2mm}





\textbf{Bayesian networks.} Here, we deal with two separate BNs. One, before the \textsf{Twin} node is even considered (Figure \ref{fig:twinless}), and one with the \textsf{Twin} node (Figure \ref{fig:twin}). The CPTs for the no-twin version are in agreement with those in the ones in the Twin case. Since the original example didn't specify exact probabilities, we came up with some plausible values.




\begin{figure}[H]
\scalebox{1.7}{
\begin{subfigure}[!ht]{0.3\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300}
graphviz.plot(DunnitNoTwinDAG, layout = "twopi")
```
\end{subfigure}} 
\hspace{-0.8cm}\scalebox{.8}{\begin{subfigure}[!ht]{0.2\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300}
CPkable0("DunnitNoTwinBN","M")
CPkable1("DunnitNoTwinBN","G")
```
\end{subfigure}  }
 \hspace{0.5cm}\scalebox{.8}{\begin{subfigure}[!ht]{0.2\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%", dpi = 300}

CPkable1("DunnitNoTwinBN","I")
CPkable1("DunnitNoTwinBN","W")
```
\end{subfigure}}
\caption{Twin-less BN for the \textsf{Dunnit} problem.}
\label{fig:twinless}
\end{figure}



\begin{figure}[H]
\scalebox{1.7}{
\begin{subfigure}[!ht]{0.4\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300}
graphviz.plot(DunnitDAG, layout = "twopi")
```
\end{subfigure}} 
\hspace{-1cm}\scalebox{.8}{\begin{subfigure}[!ht]{0.3\textwidth}
```{r,echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE, fig.show = "hold", out.width = "70%", dpi = 300}
CPkable2("DunnitBN","W")
```
\end{subfigure}}
\caption{BN for the \textsf{Dunnit} problem. The key difference for the twin version lies in the construction of the CPT for \textsf{W}. The table gives conditional probabilities for \textsf{W} given various joint states of \textsf{Tw} and \textsf{G}.}
\label{fig:twin}
\end{figure}




\textbf{Results.} 
Coherence calculations result in Table \@ref(tab:dunnitCoherence) and how they fare with respect to the desideratum is displayed in Table \@ref(tab:dunnitDesiderata). 

```{r, echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300, message = FALSE, warning = FALSE}
library(gRain)
library(bnlearn)
library(rje)
library(useful)
source("../code/utils/CombinationsBN.R")
Dunnit <- c("M","G","W","I")
DunnitTwin<- c("M","Tw","G","W","I")
# #

DunnitNoTwinTable <- CoherencesTableNarr(list(DunnitNoTwinBN),
                                         scenariosList = list(Dunnit),
                                         statesList   = list(c("1","1","1","1")),
                                         exampleName = "Dunnit"
)

  

DunnitTwinTable <- CoherencesTableNarr(list(DunnitBN),
  scenariosList = list(DunnitTwin),
  statesList   = list(c("1","1","1","1","1")),
  exampleName = "Dunnit"
)

DunnitTableSeparate <- rbind(DunnitNoTwinTable,DunnitTwinTable)
```




<!-- ```{r, echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE,  fig.show = "hold", out.width = "70%", dpi = 300} -->
<!-- load("../calculations/RdataObjects/DunnitTableSeparate.Rda") -->
<!-- load("../calculations/RdataObjects/DunnitResultsSeparate.Rda") -->


<!-- colnames(DunnitTableSeparate) <- c("OG","OGen","Sh","ShGen","Fit","DM","R","S") -->
<!-- colnames(DunnitResultsSeparate) <- c("OG","OGen","Sh","ShGen","Fit","DM","R","S") -->
<!-- DunnitTableSeparate <- DunnitTableSeparate[,-7] -->
<!-- DunnitResultsSeparate <- DunnitResultsSeparate[,-7] -->
<!-- ``` -->


```{r dunnitCoherence, echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300}
library(tidyverse)
round(DunnitTableSeparate,3) %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, caption = "Coherence scores for the Dunnit scenario (rounded).") %>%
  kable_styling(latex_options=c("striped","scale_down","HOLD_position"))
```

```{r, echo=FALSE,eval=TRUE,fig.align = "center",cache=TRUE,  fig.show = "hold", out.width = "70%", dpi = 300, message = FALSE, warning = FALSE}
DunnitLessTwin <- DunnitTableSeparate[1,] < DunnitTableSeparate[2,] 
DunnitResultsSeparate <- as.data.frame(DunnitLessTwin)
rownames(DunnitResultsSeparate) <- c("Dunnit: Dunnit$<$Twin")
```




```{r dunnitDesiderata, echo=FALSE,eval=TRUE,fig.align = "center",cache=FALSE,  fig.show = "hold", out.width = "70%", dpi = 300}
library(tidyverse)
library(knitr)
DunnitResultsSeparate %>%  kable(format = "latex",booktabs=T,
                        linesep = "",  escape = FALSE, caption = "Desideratum satisfaction for the Dunnit scenario.") %>%
  kable_styling(latex_options=c("striped","scale_down","HOLD_position"))
```






















































# References {-}

